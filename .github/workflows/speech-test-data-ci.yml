# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

###############################################################################
#
# Custom Speech Continuous Improvement Pipeline for GitHub Actions
#
###############################################################################

name: SpeechTestDataCI

on:
  push:
    # Execute on pushes to master.
    branches:
      - master
    # The push must include updates to testing data.
    paths:
      # The path from the root of the repository to a .zip with .wav files and a
      # .txt transcript used for testing.
      - "testing/audio-and-trans.zip"
    tags:
      # The workflow may be triggered with or without changes to testing data by
      # pushing a tag starting with `BASELINE`, like `BASELINE000`. To push a
      # tag, run `git tag -a <<TAG>>` then `git push origin <<TAG>>`.
      - BASELINE
      - BASELINE**

env:
  # V2 Custom Speech models can be either "Acoustic" or "Language" models. The
  # proper paths to the training data for the specific model type should be set
  # in the `speech-train-data-ci-cd.yml` environment variables.
  CUSTOM_SPEECH_MODEL_KIND: "Language"
  # See Language Support for available locales:
  # https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support
  SPEECH_LOCALE: "en-us"
  #############################################################################
  # Testing Data
  #############################################################################
  # The name and extension of the .txt transcript file that will be extracted
  # from `testZipSourcePath`.
  TEST_TRANS_FILE: "trans.txt"
  # The path from the root of the repository to a .zip with .wav files and a
  # .txt transcript used for testing.
  TEST_ZIP_SOURCE_PATH: "testing/audio-and-trans.zip"

jobs:
  #############################################################################
  #
  #   Workflow Setup - Used for updates to any data along with releasing.
  #
  #############################################################################

  setup:
    name: Workflow setup
    runs-on: ubuntu-latest

    steps:
      # https://github.com/Azure/azure-cli
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Create the test-results container if it does not exist
        run: |
          results_container_exists=$(az storage container exists --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --name test-results --auth-mode login | jq '.exists')
          if [ $results_container_exists != 'true' ]
          then
            az storage container create --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --name test-results --auth-mode login
            echo CREATED TEST-RESULTS CONTAINER.
          fi

      - name: Create the configuration container if it does not exist
        run: |
          config_container_exists=$(az storage container exists --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --name configuration --auth-mode login | jq '.exists')
          if [ $config_container_exists != 'true' ]
          then
            az storage container create --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --name configuration --public-access blob --auth-mode login
            echo CREATED CONFIGURATION CONTAINER.
          fi

  #############################################################################
  #
  #   Continuous Integration - handle updates to testing data.
  #
  #############################################################################

  test_data_update:
    name: Test benchmark model
    runs-on: ubuntu-latest
    # Execute when setup finishes executing and passes.
    needs: setup

    steps:
      - name: Checkout the repository
        uses: actions/checkout@v2
        with:
          # Indicates all history.
          fetch-depth: "0"
          # lfs: true

      # - name: Checkout LFS objects
      #   run: git lfs checkout

      # Set environment variables needed throughout the workflow, including
      # those specific to whether the workflow was triggered by updating test
      # data, or by pushing a BASELINE** tag.
      - name: Set environment variables
        run: |
          echo "::set-env name=TEST_AUDIO_ZIP_FILE::test-audio.zip"
          echo "::set-env name=TEST_BUILD_FOLDER_PATH::build-speech-test"
          if [[ ${GITHUB_REF/refs\/tags\//} == BASELINE* ]]
          then
            echo WORKFLOW TRIGGERED BY A BASELINE TAG.
            echo ::set-env name=EVENT_ID::${GITHUB_REF/refs\/tags\//}
            echo "::set-env name=HYPHEN_EVENT_NAME::baseline-tag"
            echo "::set-env name=IS_BASELINE_TEST::true"
            echo "::set-env name=UNDERSCORE_EVENT_NAME::baseline_tag"
          else
            echo WORKFLOW TRIGGERED BY A TEST DATA UPDATE.
            echo "::set-env name=EVENT_ID::$(git rev-parse --short HEAD)"
            echo "::set-env name=HYPHEN_EVENT_NAME::test-data-update"
            echo "::set-env name=UNDERSCORE_EVENT_NAME::test_data_update"
          fi

      # https://github.com/msimecek/Azure-Speech-CLI
      - name: Install and configure Azure Speech CLI
        run: |
          dotnet tool install -g azurespeechcli --version 1.5.2
          speech config set -n ${{ secrets.SPEECH_PROJECT_NAME }} -k ${{ secrets.SPEECH_SUBSCRIPTION_KEY }} -r ${{ secrets.SPEECH_RESOURCE_REGION }} -s

      #########################################################################
      # Test the Custom Speech model.
      #########################################################################

      # Assemble the Audio + Human-Labeled Transcript in the proper format and
      # upload the data.
      #
      # Check that the data has been successfully uploaded with
      # [[${my_variable//-/} =~ ^[[:xdigit:]]{32}$]] which will return true if
      # the variable is a valid GUID with 32 hexadecimal characters.
      - name: Upload audio and human transcript testing data
        run: |
          unzip ${{ env.TEST_ZIP_SOURCE_PATH }} -d ${{ env.TEST_BUILD_FOLDER_PATH }}
          zip -r ${{ env.TEST_BUILD_FOLDER_PATH }}/${{ env.TEST_AUDIO_ZIP_FILE }} ${{ env.TEST_BUILD_FOLDER_PATH }} -x "*.txt"
          speech dataset create -n audio_trans_test_${{ env.EVENT_ID }} -a ${{ env.TEST_BUILD_FOLDER_PATH }}/${{ env.TEST_AUDIO_ZIP_FILE }} -t ${{ env.TEST_BUILD_FOLDER_PATH }}/${{ env.TEST_TRANS_FILE }} --wait > ${{ env.TEST_BUILD_FOLDER_PATH }}/audio-trans-test-upload.txt
          audio_trans_test_id=$(cat ${{ env.TEST_BUILD_FOLDER_PATH }}/audio-trans-test-upload.txt | sed -n '3p')
          if ! [[ ${audio_trans_test_id//-/} =~ ^[[:xdigit:]]{32}$ ]]
          then
            echo "::error ::Failed to upload audio and human-labeled transcript testing data. Check that the correct paths are defined in environment variables or re-run all jobs."
            exit 1
          fi
          echo "::set-env name=AUDIO_TRANS_TEST_ID::$(echo $audio_trans_test_id)"

      # If a benchmark model exists, it will be tested later in the workflow.
      #
      # CUSTOM_SPEECH_MODEL_KIND will be used to filter results from the `speech
      # model list` command to get the benchmark Speech model of the same kind.
      #
      # Check that the benchmark model has been successfully downloaded with
      # [[${my_variable//-/} =~ ^[[:xdigit:]]{32}$]] which will return true if
      # the variable is a valid GUID with 32 hexadecimal characters.
      - name: Get the benchmark model
        run: |
          speech model list > ${{ env.TEST_BUILD_FOLDER_PATH }}/speech-model-list.txt
          sed -i "/${{ env.CUSTOM_SPEECH_MODEL_KIND }}/!d" ${{ env.TEST_BUILD_FOLDER_PATH }}/speech-model-list.txt
          custom_speech_model_id=$(cat ${{ env.TEST_BUILD_FOLDER_PATH }}/speech-model-list.txt | tail -1 | awk '{print $1;}')
          if [[ ${custom_speech_model_id//-/} =~ ^[[:xdigit:]]{32}$ ]]
          then
            echo IF THIS IS NOT A BASELINE TEST, TEST THE BENCHMARK CUSTOM SPEECH MODEL WITH GUID: $custom_speech_model_id
            echo "::set-env name=MODEL_ID::$(echo $custom_speech_model_id)"
          else
            echo NO EXISTING CUSTOM SPEECH MODELS. TEST THE LATEST BASELINE MODEL.
            echo "::set-env name=INITIAL_MODEL_EXISTS::false"
            echo "::set-env name=IS_BASELINE_TEST::true"
          fi

      # If a benchmark model does not exist, or if a user pushed a tag beginning
      # with `BASELINE`, get the latest baseline model.
      #
      # Check that the baseline model has been successfully downloaded with
      # [[${my_variable//-/} =~ ^[[:xdigit:]]{32}$]] which will return true if
      # the variable is a valid GUID with 32 hexadecimal characters.
      - name: Get the baseline model
        if: env.IS_BASELINE_TEST == 'true'
        run: |
          speech model list-scenarios --locale ${{ env.SPEECH_LOCALE }} --simple > ${{ env.TEST_BUILD_FOLDER_PATH }}/baseline-models.txt
          baseline_model_id=$(head -n 1 ${{ env.TEST_BUILD_FOLDER_PATH }}/baseline-models.txt)
          if ! [[ ${baseline_model_id//-/} =~ ^[[:xdigit:]]{32}$ ]]
          then
            echo "::error ::Failed to get the latest baseline model. Possibly re-run all jobs."
            exit 1
          fi
          echo TEST THE LATEST BASELINE MODEL WITH GUID: $baseline_model_id
          echo "::set-env name=MODEL_ID::$(echo $baseline_model_id)"

      # Test with Speech.
      #
      # Check that the test has been successfully created with
      # [[${my_variable//-/} =~ ^[[:xdigit:]]{32}$]] which will return true if
      # the variable is a valid GUID with 32 hexadecimal characters.
      - name: Test the benchmark or baseline model
        run: |
          speech test create -n test_from_${{ env.UNDERSCORE_EVENT_NAME }}_${{ env.EVENT_ID }} -a ${{ env.AUDIO_TRANS_TEST_ID }} -m ${{ env.MODEL_ID }} -lm ${{ env.MODEL_ID }} --wait > ${{ env.TEST_BUILD_FOLDER_PATH }}/test-output.txt
          test_id=$(cat ${{ env.TEST_BUILD_FOLDER_PATH }}/test-output.txt | sed -n '3p')
          if ! [[ ${test_id//-/} =~ ^[[:xdigit:]]{32}$ ]]
          then
            echo "::error ::Failed to test the Custom Speech model. Possibly re-run all jobs."
            exit 1
          fi
          echo "::set-env name=TEST_ID::$(echo $test_id)"

      - name: Delete testing datasets
        run: |
          speech dataset delete ${{ env.AUDIO_TRANS_TEST_ID }}
          echo DELETED AUDIO+HUMAN-LABELED TRANSCRIPT TESTING DATA.

      # Get the content from the test and remove the first line, which is
      # logging, so the result is a JSON file.
      - name: Store JSON test output
        run: |
          test_summary_file_name="test-summary-from-${{ env.HYPHEN_EVENT_NAME }}-${{ env.EVENT_ID }}.json"
          echo "::set-env name=TEST_SUMMARY_FILE::$(echo $test_summary_file_name)"
          speech test show ${{ env.TEST_ID }} > ${{ env.TEST_BUILD_FOLDER_PATH }}/$test_summary_file_name
          sed -i '1d' ${{ env.TEST_BUILD_FOLDER_PATH }}/$test_summary_file_name

      #########################################################################
      # Archive test summary and test results in Blob
      #########################################################################

      # https://github.com/Azure/azure-cli
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Save test summary in Azure Blob
        uses: azure/CLI@v1
        with:
          inlineScript: az storage blob upload --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --container-name test-results --name ${{ env.TEST_SUMMARY_FILE }} --file ${{ env.TEST_BUILD_FOLDER_PATH }}/${{ env.TEST_SUMMARY_FILE }} --auth-mode login

      - name: Save test results in Azure Blob
        run: |
          results_url=$(jq '.resultsUrl' ${{ env.TEST_BUILD_FOLDER_PATH }}/${{ env.TEST_SUMMARY_FILE }} | xargs)
          curl $results_url -o "test-results.txt"
          az storage blob upload --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --container-name test-results --name test-results-from-${{ env.HYPHEN_EVENT_NAME }}-${{ env.EVENT_ID }}.txt --file test-results.txt --auth-mode login

      # Delete the test. This must be done after the test results file is
      # generated, as the resultsUrl will only be available while the test
      # exists.
      - name: Delete test
        run: |
          speech test delete ${{ env.TEST_ID }}
          echo DELETED TEST.

      - name: Verify the configuration file exists
        run: az storage blob exists --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --container-name configuration --name benchmark-test.txt --auth-mode login | jq '.exists' | xargs -I {} echo "::set-env name=BENCHMARK_BLOB_EXISTS::{}"

      # The configuration container has a file, benchmark-test.txt, that
      # contains the name of the test summary file that was output from testing
      # the current benchmark model.
      #
      # If there is no current benchmark-test.txt, no initial model, or if the
      # workflow triggered as the results of a test data update, upload the test
      # summary from the current run of the workflow.
      - name: Update benchmark in configuration file
        if: env.IS_BASELINE_TEST != 'true' || env.BENCHMARK_BLOB_EXISTS == 'false' || env.INITIAL_MODEL_EXISTS == 'false'
        run: |
          echo ${{ env.TEST_SUMMARY_FILE }} > ${{ env.TEST_BUILD_FOLDER_PATH }}/benchmark-test.txt
          az storage blob upload --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --container-name configuration --name benchmark-test.txt --file ${{ env.TEST_BUILD_FOLDER_PATH }}/benchmark-test.txt --auth-mode login
