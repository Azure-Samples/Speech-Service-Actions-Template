# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

###############################################################################
#
# Custom Speech Continuous Improvement Pipeline for GitHub Actions
#
###############################################################################

name: SpeechTestDataCI

on:
  push:
    # Execute on pushes to master.
    branches:
      - master
    # The push must include updates to testing data.
    paths:
      # The path from the root of the repository to a .zip with .wav files and a
      # .txt transcript used for testing.
      - "testing/audio-and-trans.zip"
    tags:
      # The workflow may be triggered with or without changes to testing data by
      # pushing a tag starting with `BASELINE`, like `BASELINE000`. To push a
      # tag, run `git tag -a <<TAG>>` then `git push origin <<TAG>>`.
      - BASELINE
      - BASELINE**

env:
  # V2 Custom Speech models can be either "Acoustic" or "Language" models. The
  # proper paths to the training data for the specific model type should be set
  # in the `speech-train-data-ci-cd.yml` environment variables.
  CUSTOM_SPEECH_MODEL_KIND: "Language"
  # See Language Support for available locales:
  # https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support
  SPEECH_LOCALE: "en-US"
  #############################################################################
  # Testing Data
  #############################################################################
  # The name and extension of the .txt transcript file that will be extracted
  # from `testZipSourcePath`.
  TEST_TRANS_FILE: "trans.txt"
  # The path from the root of the repository to a .zip with .wav files and a
  # .txt transcript used for testing.
  TEST_ZIP_SOURCE_PATH: "testing/audio-and-trans.zip"
  # version of Speech CLI tool to install and use
  SPX_VERSION: "1.0.0"

jobs:
  #############################################################################
  #
  #   Workflow Setup - Used for updates to any data along with releasing.
  #
  #############################################################################

  setup:
    name: Workflow setup
    runs-on: ubuntu-latest

    steps:
      # https://github.com/Azure/azure-cli
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Create the test-results container if it does not exist
        run: |
          results_container_exists=$(az storage container exists --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --name test-results --auth-mode login | jq '.exists')
          if [ $results_container_exists != 'true' ]
          then
            az storage container create --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --name test-results --auth-mode login
            echo CREATED TEST-RESULTS CONTAINER.
          fi
      - name: Create the configuration container if it does not exist
        run: |
          config_container_exists=$(az storage container exists --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --name configuration --auth-mode login | jq '.exists')
          if [ $config_container_exists != 'true' ]
          then
            az storage container create --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --name configuration --public-access blob --auth-mode login
            echo CREATED CONFIGURATION CONTAINER.
          fi
  #############################################################################
  #
  #   Continuous Integration - handle updates to testing data.
  #
  #############################################################################

  test_data_update:
    name: Test benchmark model
    runs-on: ubuntu-latest
    # Execute when setup finishes executing and passes.
    needs: setup

    steps:
      - name: Checkout the repository
        uses: actions/checkout@v2
        with:
          # Indicates all history.
          fetch-depth: "0"
          # lfs: true

      # - name: Checkout LFS objects
      #   run: git lfs checkout

      # Set environment variables needed throughout the workflow, including
      # those specific to whether the workflow was triggered by updating test
      # data, or by pushing a BASELINE** tag.
      - name: Set environment variables
        run: |
          echo "TEST_AUDIO_ZIP_FILE=test-audio.zip" >> $GITHUB_ENV
          echo "TEST_BUILD_FOLDER_PATH=build-speech-test" >> $GITHUB_ENV
          if [[ ${GITHUB_REF/refs\/tags\//} == BASELINE* ]]
          then
            echo WORKFLOW TRIGGERED BY A BASELINE TAG.
            eid=${GITHUB_REF/refs\/tags\//}
            echo "EVENT_ID=${eid}" >> $GITHUB_ENV
            echo "HYPHEN_EVENT_NAME=baseline-tag" >> $GITHUB_ENV
            echo "IS_BASELINE_TEST=true" >> $GITHUB_ENV
            echo "UNDERSCORE_EVENT_NAME=baseline_tag" >> $GITHUB_ENV
          else
            echo WORKFLOW TRIGGERED BY A TEST DATA UPDATE.
            echo "EVENT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
            echo "HYPHEN_EVENT_NAME=test-data-update" >> $GITHUB_ENV
            echo "UNDERSCORE_EVENT_NAME=test_data_update" >> $GITHUB_ENV
          fi
      # https://github.com/Azure-Samples/cognitive-services-speech-tools
      - name: Install and configure Speech CLI
        run: |
          dotnet tool install -g Microsoft.CognitiveServices.Speech.CLI --version ${{ env.SPX_VERSION }}
          spx config @name --set ${{ secrets.SPEECH_PROJECT_NAME }} 
          spx config @key --set ${{ secrets.SPEECH_SUBSCRIPTION_KEY }} 
          spx config @region --set ${{ secrets.SPEECH_RESOURCE_REGION }}
      #########################################################################
      # Test the Custom Speech model.
      #########################################################################

      # Assemble the Audio + Human-Labeled Transcript in the proper format and
      # upload the data.
      #
      # Check that the data has been successfully uploaded with
      # [[${my_variable//-/} =~ ^[[:xdigit:]]{32}$]] which will return true if
      # the variable is a valid GUID with 32 hexadecimal characters.
      - name: Upload audio and human transcript testing data
        if: ${{ env.TEST_ZIP_SOURCE_PATH && env.TEST_ZIP_SOURCE_PATH != '' }}
        run: |
          spx csr dataset upload --data $TEST_ZIP_SOURCE_PATH --kind Acoustic --name audio_trans_test_${EVENT_ID} --output url @my.testing.datasets --wait
          audio_trans_test_id=$(cat my.testing.datasets | tail -c 36)
          if ! [[ ${audio_trans_test_id//-/} =~ ^[[:xdigit:]]{32}$ ]]
          then
            echo "::error ::Failed to upload audio and human-labeled transcript testing data. Check that the correct paths are defined in environment variables or re-run all jobs."
            exit 1
          fi
          echo "AUDIO_TRANS_TEST_ID=$(echo $audio_trans_test_id)" >> $GITHUB_ENV
      # If a benchmark model exists, it will be tested later in the workflow.
      #
      # Check that the benchmark model has been successfully downloaded with
      # [[${my_variable//-/} =~ ^[[:xdigit:]]{32}$]] which will return true if
      # the variable is a valid GUID with 32 hexadecimal characters.
      - name: Get the benchmark model
        run: |
          spx csr model list --models --output url @my.benchmark.model.url
          custom_speech_model_id=$(tail -1 my.benchmark.model.url | tail -c 36)
          if [[ ${custom_speech_model_id//-/} =~ ^[[:xdigit:]]{32}$ ]]
          then
            echo IF THIS IS NOT A BASELINE TEST, TEST THE BENCHMARK CUSTOM SPEECH MODEL WITH GUID: $custom_speech_model_id
            echo "MODEL_ID=$(echo $custom_speech_model_id)" >> $GITHUB_ENV
          else
            echo NO EXISTING CUSTOM SPEECH MODELS. TEST THE LATEST BASELINE MODEL.
            echo "INITIAL_MODEL_EXISTS=false" >> $GITHUB_ENV
            echo "IS_BASELINE_TEST=true" >> $GITHUB_ENV
          fi
      # If a benchmark model does not exist, or if a user pushed a tag beginning
      # with `BASELINE`, get the latest baseline model.
      #
      # Check that the baseline model has been successfully downloaded with
      # [[${my_variable//-/} =~ ^[[:xdigit:]]{32}$]] which will return true if
      # the variable is a valid GUID with 32 hexadecimal characters.
      - name: Get the baseline model
        if: ${{ env.IS_BASELINE_TEST == 'true' }}
        run: |
          spx csr model list --models --output json models.json
          jq --arg LOC "$SPEECH_LOCALE" '.values[]|select(.locale==$LOC).baseModel.self' models.json | tr -d \" > models.txt
          rm models.json
          tail -1 models.txt | tr -d '[:space:]' > my.base.model.url
          baseline_model_id=$(cat my.base.model.url | tail -c 36)
          if ! [[ ${baseline_model_id//-/} =~ ^[[:xdigit:]]{32}$ ]]
          then
            echo "::error ::Failed to get the latest baseline model. Possibly re-run all jobs."
            exit 1
          fi
          echo TEST THE LATEST BASELINE MODEL WITH GUID: $baseline_model_id
          echo "MODEL_ID=$(echo $baseline_model_id)" >> $GITHUB_ENV
      # Test with Speech.
      #
      # Check that the test has been successfully created with
      # [[${my_variable//-/} =~ ^[[:xdigit:]]{32}$]] which will return true if
      # the variable is a valid GUID with 32 hexadecimal characters.
      - name: Test the benchmark or baseline model
        run: |
          spx csr evaluation create --name test_from_${UNDERSCORE_EVENT_NAME}_${EVENT_ID} --model1 @my.base.model.url --model2 @my.benchmark.model.url --dataset @my.testing.datasets --output url @my.test.result --wait 
          test_id=$(tail -1 my.test.result | tail -c 36)
          if ! [[ ${test_id//-/} =~ ^[[:xdigit:]]{32}$ ]]
          then
            echo "::error ::Failed to test the Custom Speech model. Possibly re-run all jobs."
            exit 1
          fi
          echo "TEST_ID=$(echo $test_id)" >> $GITHUB_ENV
      - name: Delete testing datasets
        run: |
          spx csr dataset delete --foreach dataset in my.testing.datasets
          echo DELETED AUDIO+HUMAN-LABELED TRANSCRIPT TESTING DATA.
      # Get the content from the test and remove the first line, which is
      # logging, so the result is a JSON file.
      - name: Store JSON test output
        run: |
          spx csr evaluation status --evaluation @my.test.result --output json ${TEST_BUILD_FOLDER_PATH}/test_json_${UNDERSCORE_EVENT_NAME}_${EVENT_ID}
      #########################################################################
      # Archive test summary and test results in Blob
      #########################################################################

      # https://github.com/Azure/azure-cli
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Save test summary in Azure Blob
        uses: azure/CLI@v1
        with:
          inlineScript: az storage blob upload --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --container-name test-results --name test_json_${UNDERSCORE_EVENT_NAME}_${EVENT_ID} --file ${TEST_BUILD_FOLDER_PATH}/test_json_${UNDERSCORE_EVENT_NAME}_${EVENT_ID} --auth-mode login

      - name: Save test results in Azure Blob
        run: |
          cat ${TEST_BUILD_FOLDER_PATH}/test_json_${UNDERSCORE_EVENT_NAME}_${EVENT_ID} > test-results.txt
          az storage blob upload --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --container-name test-results --name test-results-from-${HYPHEN_EVENT_NAME}-${EVENT_ID}.txt --file test-results.txt --auth-mode login
      # Delete the test. This must be done after the test results file is
      # generated, as the resultsUrl will only be available while the test
      # exists.
      - name: Delete test
        run: |
          spx csr evaluation delete --evaluation @my.test.result
          echo DELETED TEST.

      # Delete all potentially sensitive config variables from build machine
      - name: Delete Test configuration 
        run: |
          spx config @spx.defaults --set @@none
          echo TEST CONFIGURATION DELETED
  
      - name: Verify the configuration file exists
        run: az storage blob exists --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --container-name configuration --name benchmark-test.txt --auth-mode login | jq '.exists' | xargs -I {} echo "BENCHMARK_BLOB_EXISTS={}" >> $GITHUB_ENV

      # The configuration container has a file, benchmark-test.txt, that
      # contains the name of the test summary file that was output from testing
      # the current benchmark model.
      #
      # If there is no current benchmark-test.txt, no initial model, or if the
      # workflow triggered as the results of a test data update, upload the test
      # summary from the current run of the workflow.
      - name: Update benchmark in configuration file
        if: ${{ env.IS_BASELINE_TEST != 'true' || env.BENCHMARK_BLOB_EXISTS == 'false' || env.INITIAL_MODEL_EXISTS == 'false' }}
        run: |
          echo test_json_${UNDERSCORE_EVENT_NAME}_${EVENT_ID} > ${TEST_BUILD_FOLDER_PATH}/benchmark-test.txt
          az storage blob upload --account-name ${{ secrets.STORAGE_ACCOUNT_NAME }} --container-name configuration --name benchmark-test.txt --file ${TEST_BUILD_FOLDER_PATH}/benchmark-test.txt --auth-mode login